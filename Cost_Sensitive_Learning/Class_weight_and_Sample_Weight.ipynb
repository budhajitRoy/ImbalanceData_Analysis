{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "931a6873",
   "metadata": {},
   "source": [
    "## Misclassification cost as part of training\n",
    "\n",
    "There are 2 ways in which we can introduce cost into the learning function of the algorithm with Scikit-learn:\n",
    "\n",
    "- Defining the **class_weight** parameter for those estimators that allow it, when we set the estimator\n",
    "- Passing a **sample_weight** vector with the weights for every single observation, when we fit the estimator.\n",
    "\n",
    "\n",
    "With both the **class_weight** parameter or the **sample_weight** vector, we indicate that the loss function should be modified to accommodate the class imbalance and the cost attributed to each misclassification.\n",
    "\n",
    "## parameters\n",
    "\n",
    "**class_weight**: can take 'balanced' as argument, in which case it will use the balance ratio as weight. Alternatively, it can take a dictionary with {class: penalty}, pairs. In this case, it penalizes mistakes in samples of class[i] with class_weight[i].\n",
    "\n",
    "So if class_weight = {0:1, and 1:10}, misclassification of observations of class 1 are penalized 10 times more than misclassification of observations of class 0.\n",
    "\n",
    "**sample_weight** is a vector of the same length as y, containing the weight or penalty for each individual observation. In principle, it is more flexible, because it allows us to set weights to the observations and not to the class as a whole. So in this case, for example we could set up higher penalties for fraudulent applications that are more costly (money-wise)than to those fraudulent applications that are of little money.\n",
    "\n",
    "## Important\n",
    "\n",
    "If you use both class_weight and sample_weight, the final penalty will be **the combination of the 2**, so be very careful\n",
    "\n",
    "## Demo\n",
    "\n",
    "In this notebook I will introduce cost-sensitive learning to Logistic Regression. But we can do the same with almost every other classifier in Scikit-learn using **sample_weight** or, using **Class_weight** in those estimators that have that attribute.\n",
    "\n",
    "## Classifiers that support class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0224145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a533ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "ExtraTreeClassifier\n",
      "ExtraTreesClassifier\n",
      "LinearSVC\n",
      "LogisticRegression\n",
      "LogisticRegressionCV\n",
      "NuSVC\n",
      "PassiveAggressiveClassifier\n",
      "Perceptron\n",
      "RandomForestClassifier\n",
      "RidgeClassifier\n",
      "RidgeClassifierCV\n",
      "SGDClassifier\n",
      "SVC\n"
     ]
    }
   ],
   "source": [
    "# lets try to find all classifiers with the attribute 'class_weight'\n",
    "\n",
    "# Let's find out which classifiers from sklearn support class_weight\n",
    "# as part of the __init__ method, that is, when we set the m up\n",
    "\n",
    "from sklearn.utils import all_estimators\n",
    "\n",
    "estimators = all_estimators(type_filter='classifier')\n",
    "\n",
    "for name,class_ in estimators:\n",
    "    try:\n",
    "        if hasattr(class_(), 'class_weight'):\n",
    "            print(name)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98636f7b",
   "metadata": {},
   "source": [
    "Not all classifiers supports class_weight. For those which don't, like GradientBoostingClassifier, we can still use sample_weight when we fit the estimator.\n",
    "\n",
    "## Logistic Regression with class_weight and sample weight\n",
    "\n",
    "In this demo, we are going to introduce the misclassification cost in Logistic Regression, using class_weight and then sample_weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12569989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95f66ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3566</th>\n",
       "      <td>69.43</td>\n",
       "      <td>21.05</td>\n",
       "      <td>0.97</td>\n",
       "      <td>26.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>1539.3</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1813.6</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>1015.2</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90644</th>\n",
       "      <td>89.27</td>\n",
       "      <td>24.73</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>-25.5</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2791.3</td>\n",
       "      <td>1.49</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3785.4</td>\n",
       "      <td>-1.14</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-103.0</td>\n",
       "      <td>1286.1</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21409</th>\n",
       "      <td>78.88</td>\n",
       "      <td>24.75</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1468.9</td>\n",
       "      <td>0.89</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>965.7</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>833.4</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.93</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28471</th>\n",
       "      <td>92.74</td>\n",
       "      <td>21.74</td>\n",
       "      <td>0.38</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1080.8</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.44</td>\n",
       "      <td>19.5</td>\n",
       "      <td>-85.0</td>\n",
       "      <td>...</td>\n",
       "      <td>806.1</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>2.27</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.58</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40266</th>\n",
       "      <td>75.58</td>\n",
       "      <td>24.72</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1539.8</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.90</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-74.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2081.4</td>\n",
       "      <td>-1.94</td>\n",
       "      <td>5.11</td>\n",
       "      <td>23.0</td>\n",
       "      <td>-111.0</td>\n",
       "      <td>903.4</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1     2     3     4       5     6     7     8     9  ...  \\\n",
       "3566   69.43  21.05  0.97  26.0  15.5  1539.3  1.58  0.38  -3.0 -73.0  ...   \n",
       "90644  89.27  24.73 -0.79 -25.5  32.0  2791.3  1.49 -0.98 -20.0 -91.0  ...   \n",
       "21409  78.88  24.75 -1.41 -14.0 -11.0  1468.9  0.89 -0.29   4.0 -93.0  ...   \n",
       "28471  92.74  21.74  0.38  20.0 -12.0  1080.8  0.60  0.44  19.5 -85.0  ...   \n",
       "40266  75.58  24.72 -1.00 -32.0  45.0  1539.8  0.41  0.90   9.0 -74.5  ...   \n",
       "\n",
       "           65    66    67    68     69      70    71    72    73  target  \n",
       "3566   1813.6  1.75  0.47   0.0  -84.0  1015.2 -0.64  0.05 -0.69      -1  \n",
       "90644  3785.4 -1.14  0.41   0.0 -103.0  1286.1  1.28  0.33 -0.02      -1  \n",
       "21409   965.7  0.95 -0.54   7.0  -84.0   833.4  0.53  0.28  0.93      -1  \n",
       "28471   806.1 -0.49  2.27  10.0  -38.0    85.0  0.61  0.43  0.58      -1  \n",
       "40266  2081.4 -1.94  5.11  23.0 -111.0   903.4  0.53  0.18 -0.25      -1  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets import dataset\n",
    "\n",
    "df = pd.read_csv('..\\kdd2004.csv').sample(10000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aab2de04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 75)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61249eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    0.9916\n",
       " 1    0.0084\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check balance ratio\n",
    "df['target'].value_counts()/len(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ea9d700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 74), (3000, 74))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the data into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('target', axis =1),\n",
    "                                                   df['target'],\n",
    "                                                   test_size=0.3,\n",
    "                                                   random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bccbd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to call logistic regression model\n",
    "\n",
    "def run_log(X_train, X_test, y_train, y_test,class_weight):\n",
    "    \n",
    "    log = LogisticRegression(penalty='l2',\n",
    "                             solver='newton-cg',\n",
    "                             max_iter=10,\n",
    "                             class_weight=class_weight,  # weights/cost\n",
    "                             random_state=0,\n",
    "                            n_jobs=2)\n",
    "    \n",
    "    log.fit(X_train, y_train)\n",
    "    \n",
    "    train_preds = log.predict_proba(X_train)\n",
    "    test_preds = log.predict_proba(X_test)\n",
    "    \n",
    "    print('Train ROC: {}'.format(roc_auc_score(y_train, train_preds[:,1])))\n",
    "    print('Test ROC: {}'.format(roc_auc_score(y_test, test_preds[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8df44177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC: 0.9321113528456024\n",
      "Test ROC: 0.8492481718179666\n"
     ]
    }
   ],
   "source": [
    "# running the log model without the class weight values\n",
    "# i.e. original data and no balancing\n",
    "\n",
    "run_log(X_train, X_test, y_train, y_test,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbdea36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC: 0.9912647093753396\n",
      "Test ROC: 0.9470045221811114\n"
     ]
    }
   ],
   "source": [
    "# with class_weight balanced\n",
    "# running the log model without the class weight values\n",
    "# i.e. original data and no balancing\n",
    "# this technique uses class imbalance ratio to determine the cost\n",
    "\n",
    "run_log(X_train, X_test, y_train, y_test,'balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cafdefc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC: 0.978605234099219\n",
      "Test ROC: 0.9141408478778139\n"
     ]
    }
   ],
   "source": [
    "# alternatively, we can pass a different cost\n",
    "# in a dictionary, if we know it already\n",
    "\n",
    "run_log(X_train,\n",
    "          X_test,\n",
    "          y_train,\n",
    "          y_test,\n",
    "          class_weight={-1:1, 1:10}) \n",
    "# the above  {-1:1, 1:10} means, the cost for a misclassification of an obs belonging to class 1 is 10, class 1 being minority\n",
    "# and the cost for a misclassification of an obs belonging to class 1 is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14aae1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC: 0.9813165348918891\n",
      "Test ROC: 0.916021975557798\n"
     ]
    }
   ],
   "source": [
    "# changing class weights\n",
    "run_log(X_train,\n",
    "          X_test,\n",
    "          y_train,\n",
    "          y_test,\n",
    "          class_weight={-1:1, 1:50}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6dc3afae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC: 0.9911484746722055\n",
      "Test ROC: 0.9464065478192623\n"
     ]
    }
   ],
   "source": [
    "# changing class weights\n",
    "run_log(X_train,\n",
    "          X_test,\n",
    "          y_train,\n",
    "          y_test,\n",
    "          class_weight={-1:1, 1:99}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7d4ca50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC: 0.9912495483271047\n",
      "Test ROC: 0.948013603916732\n"
     ]
    }
   ],
   "source": [
    "# changing class weights\n",
    "run_log(X_train,\n",
    "          X_test,\n",
    "          y_train,\n",
    "          y_test,\n",
    "          class_weight={-1:1, 1:120}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7781b854",
   "metadata": {},
   "source": [
    "- We should always check the class weight proportions as it might over fit to a specific class and ignores classification of other classes as well.\n",
    "- IT also seems, the more we get close to the imbalance ratio, the greater performance the model produces\n",
    "- And once the class imbalance ratio exceeds, the model performance seems to remain constant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014acc4e",
   "metadata": {},
   "source": [
    "## Using Sample Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "501d6722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression + sample weight\n",
    "\n",
    "def run_logit(X_train, X_test, y_train, y_test,sample_weight):\n",
    "    \n",
    "    log = LogisticRegression(penalty='l2',\n",
    "                             solver='newton-cg',\n",
    "                             max_iter=10,\n",
    "                             random_state=0,\n",
    "                            n_jobs=2)\n",
    "    \n",
    "    log.fit(X_train, y_train,sample_weight=sample_weight)\n",
    "    \n",
    "    train_preds = log.predict_proba(X_train)\n",
    "    test_preds = log.predict_proba(X_test)\n",
    "    \n",
    "    print('Train ROC: {}'.format(roc_auc_score(y_train, train_preds[:,1])))\n",
    "    print('Test ROC: {}'.format(roc_auc_score(y_test, test_preds[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b18654e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC: 0.9321113528456024\n",
      "Test ROC: 0.8492481718179666\n"
     ]
    }
   ],
   "source": [
    "# this is the same when we ran earlier with no class weight\n",
    "run_logit(X_train, X_test, y_train, y_test,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cff4a3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC: 0.9911484746722055\n",
      "Test ROC: 0.9464065478192623\n"
     ]
    }
   ],
   "source": [
    "sample_weight = np.where(y_train==1,99,1)\n",
    "# above means set the sample weight of that observation to be 99 if y_train of that obs == 1\n",
    "# i.e. it belongs to minority, otherwise set the sample weight to 1\n",
    "# because we are setting up sample_weight for every sample or observation\n",
    "\n",
    "run_logit(X_train, X_test, y_train, y_test,sample_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002f17f0",
   "metadata": {},
   "source": [
    "- This results is the same when we ran earlier passing class_weight = {-1:1,1:99}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d862d72e",
   "metadata": {},
   "source": [
    "**We can see that cost learning improves the performance of our model for this dataset**\n",
    "- We can try running some other models in some other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "265864fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## from imblearn datasets\n",
    "from imblearn.datasets import fetch_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fc4bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_ls = [\n",
    "    'car_eval_34',\n",
    "    'ecoli',\n",
    "    'thyroid_sick',\n",
    "    'arrhythmia',\n",
    "    'ozone_level'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12f16229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[0.49, 0.29, 0.48, ..., 0.56, 0.24, 0.35],\n",
       "        [0.07, 0.4 , 0.48, ..., 0.54, 0.35, 0.44],\n",
       "        [0.56, 0.4 , 0.48, ..., 0.49, 0.37, 0.46],\n",
       "        ...,\n",
       "        [0.61, 0.6 , 0.48, ..., 0.44, 0.39, 0.38],\n",
       "        [0.59, 0.61, 0.48, ..., 0.42, 0.42, 0.37],\n",
       "        [0.74, 0.74, 0.48, ..., 0.31, 0.53, 0.52]]),\n",
       " 'target': array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], dtype=int64),\n",
       " 'DESCR': 'ecoli'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = fetch_datasets()['ecoli']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76f1dc36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target     0     1     2    3     4     5     6\n",
       "0      -1  0.49  0.29  0.48  0.5  0.56  0.24  0.35\n",
       "1      -1  0.07  0.40  0.48  0.5  0.54  0.35  0.44\n",
       "2      -1  0.56  0.40  0.48  0.5  0.49  0.37  0.46\n",
       "3      -1  0.59  0.49  0.48  0.5  0.52  0.45  0.36\n",
       "4      -1  0.23  0.32  0.48  0.5  0.55  0.25  0.35"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data.data, data.target)\n",
    "df.head()\n",
    "\n",
    "df = df.reset_index()\n",
    "df.rename(columns = {'index':'target'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f25b26e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(336, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eff5823a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    0.895833\n",
       " 1    0.104167\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()/len(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f93b94ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to call logistic regression model\n",
    "\n",
    "def run_log1(X_train, X_test, y_train, y_test,class_weight):\n",
    "    \n",
    "    log = LogisticRegression(penalty='l2',\n",
    "                             solver='newton-cg',\n",
    "                             max_iter=10,\n",
    "                             class_weight=class_weight,  # weights/cost\n",
    "                             random_state=0,\n",
    "                            n_jobs=2)\n",
    "    \n",
    "    log.fit(X_train, y_train)\n",
    "    \n",
    "    train_preds = log.predict_proba(X_train)\n",
    "    test_preds = log.predict_proba(X_test)\n",
    "    \n",
    "    print('Train ROC: {}'.format(roc_auc_score(y_train, train_preds[:,1])))\n",
    "    print('Test ROC: {}'.format(roc_auc_score(y_test, test_preds[:,1])))\n",
    "    \n",
    "    return roc_auc_score(y_test, test_preds[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7eacd600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car_eval_34\n",
      "(1209, 21) (519, 21)\n",
      "Train ROC: 0.9987859868192854\n",
      "Test ROC: 0.9970405143381977\n",
      "Train ROC: 0.9988148918950167\n",
      "Test ROC: 0.9965812838044699\n",
      "ecoli\n",
      "(235, 7) (101, 7)\n",
      "Train ROC: 0.9302539565697461\n",
      "Test ROC: 0.9492753623188406\n",
      "Train ROC: 0.9370629370629371\n",
      "Test ROC: 0.9456521739130435\n",
      "thyroid_sick\n",
      "(2640, 52) (1132, 52)\n",
      "Train ROC: 0.8707358610817982\n",
      "Test ROC: 0.8753492952545086\n",
      "Train ROC: 0.9605818557950497\n",
      "Test ROC: 0.9328737613097803\n",
      "arrhythmia\n",
      "(316, 278) (136, 278)\n",
      "Train ROC: 0.9974424552429668\n",
      "Test ROC: 0.96484375\n",
      "Train ROC: 1.0\n",
      "Test ROC: 0.923828125\n",
      "ozone_level\n",
      "(1775, 72) (761, 72)\n",
      "Train ROC: 0.8140988436983794\n",
      "Test ROC: 0.6474259974259974\n",
      "Train ROC: 0.908009286128845\n",
      "Test ROC: 0.77001287001287\n"
     ]
    }
   ],
   "source": [
    "results_dict = {}\n",
    "for dataset in datasets_ls:\n",
    "    print(dataset)\n",
    "    \n",
    "    data = fetch_datasets()[dataset]\n",
    "    results_dict[dataset] = {}\n",
    "\n",
    "    X_train, X_test,y_train, y_test = train_test_split(data.data,\n",
    "                                                      data.target,\n",
    "                                                       test_size=0.3,\n",
    "                                                      random_state=0)\n",
    "    print(X_train.shape,X_test.shape)\n",
    "    \n",
    "    results_0 = run_log1(X_train, X_test,y_train,y_test,None)\n",
    "    results_1 = run_log1(X_train, X_test,y_train,y_test,'balanced')\n",
    "    results_dict[dataset]['Not_balanced'] = results_0\n",
    "    results_dict[dataset]['Balanced'] = results_1\n",
    "    \n",
    "    #sample_weight = np.where(y_train == 1,99,-1)\n",
    "    #run_logit(X_train,X_test,y_train,y_test,sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca242bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'car_eval_34': {'Not_balanced': 0.9970405143381977,\n",
       "  'Balanced': 0.9965812838044699},\n",
       " 'ecoli': {'Not_balanced': 0.9492753623188406, 'Balanced': 0.9456521739130435},\n",
       " 'thyroid_sick': {'Not_balanced': 0.8753492952545086,\n",
       "  'Balanced': 0.9328737613097803},\n",
       " 'arrhythmia': {'Not_balanced': 0.96484375, 'Balanced': 0.923828125},\n",
       " 'ozone_level': {'Not_balanced': 0.6474259974259974,\n",
       "  'Balanced': 0.77001287001287}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
